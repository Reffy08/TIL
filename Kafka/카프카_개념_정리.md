# 아파치 카프카(Apache Kafka) 개념 정리

아파치 카프카(Apache Kafka)에 대해서 공부하면서 아파치 카프카가 어떻게 등장했고, 무엇인지 그리고 주요 용여 및 동작 과정에 대해서 정리해본다.  

내용은 <a href="https://kafka.apache.org/documentation/" target="_blank">카프카 공식 문서</a>와 <a href="https://www.yes24.com/product/goods/99122569" target="_blank">아파치 카프카 애플리케이션 프로그래밍 with 자바</a> 책의 내용을 토대로 정리했다.  


<br/>
<br/>

## 아파치 카프카의 등장

소셜 네트워크 사이트인 링크드인(LinkedIn)에서 데이터를 생성 및 적재하기 위해서는 데이터를 생성하는 소스 애플리케이션과 데이터를 최종 적재하는 타깃 애플리케이션을 연동하는 소스코드를 작성했다. 소스 및 타깃 애플리케이션을 연결하는 파이프라인의 개수가 많아지면서 소스코드 버전 관리 이슈가 생기고, 장애도 그대로 전달됐다.  

![카프카 이전](/Kafka/images/01_prev-kafka.png)  
<a href="https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying" target="_blank">https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying</a>  

<br/>

갈수록 복잡해지는 파편화된 데이터 파이프라인의 복잡도를 낮추기 위해서 만든 시스템이 아파치 카프카다. 아파치 카프카는 각각의 애플리케이션을 연결하여 데이터를 처리하는 것이 아니라 한 곳에 모아 처리할 수 있도록 중앙 집중화해서 데이터 스트림을 한 곳에서 실시간으로 관리할 수 있게 됐다. 즉, 대용량의 데이터를 수집하고 이를 사용자들이 실시간 스트림으로 소비할 수 있게 만들어준다.  

![카프카 이후](/Kafka/images/02_after-kafka.png)  
<a href="https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying" target="_blank">https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying</a>  

<br/>

대규모의 데이터를 처리할 떄 카프카를 중앙에 배치하면서 소스 애플리케이션과 타깃 애플리케이션간의 의존을 최소화하여 결합도를 완화했다. 아파치 카프카는 데이터 파이프라인을 안정적이고 확장성 높게 운영하기 위한 좋은 방법이다.  

<br/>
<br/>

## 아파치 카프카란?

![카프카 로고](/Kafka/images/00_kafka-logo.png)

아파치 카프카의 공식문서에서는 아파치 카프카를 다음처럼 소개하고 있다.  

> Apache Kafka is an open-source distributed event streaming platform used by thousands of companies for high-performance data pipelines, streaming analytics, data integration, and mission-critical applications.
> 
> Apache Kafka는 수천 개의 기업에서 고성능 데이터 파이프라인, 스트리밍 분석, 데이터 통합 및 기업의 핵심 운영에 필수적인 애플리케이션을 위해 사용되는 오픈 소스 분산 이벤트 스트리밍 플랫폼이다.

<br/>

공식 문서에서 **이벤트 스트리밍 플랫폼**은 실시간으로 발생하는 대규모 이벤트를 처리하고 실시간 처리을 위한 플랫폼이다. 주로 분산 시스템, 실시간 데이터 처리, 이벤트 기반 아키텍처에서 사용된다.   

이벤트 스트리밍 플랫폼은 데이터를 지속적으로 스트리밍하며, 이벤트는 로그 형태로 보존된다. 이벤트가 발생할 때마다 이를 기록하고, 다양한 소비자가 이 이벤트를 반복적으로 읽을 수 있다. 이벤트 스트리밍은 데이터를 저장하고 여러 소비자가 동시에 데이터를 처리할 수 있는 환경을 제공한다. 즉, 이벤트는 비소멸적으로 저장되며 여러 번 처리될 수 있다.  

아파치 카프카는 고속의 데이터 전송을 처리하고, 대규모 데이터를 안정적으로 저장하며, 이를 실시간으로 처리할 수 있는 시스템이다. 카프카는 메모리나 DB에 저장하지 않으며 따로 캐시메모리를 구현하지 않고 파일 시스템에 저장하는데, 파일 시스템은 메모리보다 처리 속도가 현저히 느리다. 이 문제를 페이지 캐시로 디스크 입출력 속도를 높여서 해결했다.

<br/>

### 카프카의 주요 요소

- **Producer**: 프로듀서는 메시지(레코드)를 카프카 클러스터(브로커)로 전송하는 역할을 한다. 프로듀서는 특정 토픽에 메시지를 보내며, 브로커가 메시지를 토픽안의 적절한 파티션에 저장한다.
- **Consumer**: 컨슈머는 카프카 클러스터에서 메시지를 읽어오는 역할을 한다. 컨슈머는 특정 토픽에서 메시지를 소비하며, 컨슈머 그룹을 형성해서 여러 개의 컨슈머가 분산처리할 수 있다. 각 컨슈머는 독립적으로 메시지를 처리한다. 컨슈머의 수는 토픽의 파티션 수와 맞추는 것이 각 파티션에 컨슈머를 할당할 수 있으므로 작업량을 균등하게 분배할 수 있다.
- **Broker**: 브로커는 카프카 클러스터의 서버를 의미한다. 카프카는 여러 개의 브로커로 구성된 클러스터 형태로 운영되며, 각 브로커는 메시지를 저장하고 분배하는 역할을 한다. 카프카 클러스터는 하나 이상의 브로커로 구성되며, 레플리케이션을 위해서는 3개 이상의 브로커를 구성하는 것이 좋다.
- **Topic**: 토픽은 메시지가 분류되는 단위이다. 카프카는 프로듀서가 보낸 메시지를 여러 개의 파티션으로 나누어 저장하고, 각 파티션은 하나의 토픽에 속한다. 즉, 토픽은 파티션으로 구성된 로그파일의 집합이다.
- **Partition**: 파티션은 토픽 내에서 메시지(레코드)가 분할되어 저장되는 단위이다. 파티션은 로그 파일로 저장되며, 메시지는 각 파티션에 순차적으로 기록된다. 파티션은 메시지를 분산 저장하고, 여러 브로커에 걸쳐서 분배된다. 파티션은 세그먼트(Segment)라는 로그 구조를 갖는 물리적으로 저장되는 파일 단위로 구성되어있다.
- **Consumer Group**: 컨슈머 그룹은 여러 개의 컨슈머가 함께 동작하여 하나의 그룹으로 메시지를 소비하는 방식이다. 각 컨슈머는 토피그이 파티션을 나누어 처리하며, 동일한 컨슈머 그룹에 속한 컨슈머들은 중복되지 않게 메시지를 소비한다.
- **Zookeeper**: 주키퍼는 Kafka 클러스터의 메타데이터 관리 및 클러스터 상태 관리를 담당한다. 카프카는 클러스터의 구성과 노드 간의 상호 작용을 주키퍼에 의존하여 관리한다. 하지만 최근에는 주키파 없이 카프카 브로커가 동작할 수 있도록 개선된 KRaft 모드가 도입되었지만, 아직 주키퍼를 많이 사용한다. 주기퍼는 과반수 투표를 통해 리더를 선출하기 때문에 보통 홀수 개(3개 이상)의 주키퍼 서버 인스턴스를 권장한다.  

<br/>

### 카프카의 특징

- **높은 처리량**: 많은 양의 데이터를 묵음 단위로 처리하는 배치로 빠르게 처리할 수 있기 때문에 네트워크 통신 횟수를 최소화하고 대용량의 실시간 로그 데이터를 처리하는데 적합하다. 또한 파티션 단위를 통해 동일 목적의 데이터를 여러 파티션에 분배하고 데이터를 병렬 처리할 수 있다.
- **확장성**: 데이터가 얼마나 들어올지 모르는 가변적인 환경에서 안정적으로 확장 가능하도록 설계됐다. 카프카 클러스터의 브로커를 Scale in, Scale out  할 수 있다. Scale in, Scale out 과정은 클러스터의 무중단 운영을 지원한다.
- **영속성**: 영속성은 데이터를 생성한 프로그램이 종료되도 사라지지 않는 데이터 특성을 말한다. 카프카는 데이터를 메모리에 저장하지 않고 파일 시스템에 저장한다.
- **고가용성**: 3개 이상의 서버들로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하더라도 무중단으로 안전하고 지속적으로 데이터를 처리할 수 있다. 이 때 데이터 복제(replication)을 사용한다. 프로듀서로부터 전달받은 데이터를 브로커에 저장하고 나머지 브로커에 복제된 데이터를 저장한다.
- **내결함성**: Kafka는 데이터를 여러 복제본으로 저장하여 파티션 마다 여러 개의 복제본이 존재하며, 장애가 발생하면 다른 복제본으로 이를 대체해서 데이터 손실을 방지할 수 있다.
- **높은 내구성**: 카프카는 메시지를 디스크에 지속적으로 기록하고, 로그 파일에 순차적으로 저장하는 방식으로 데이터 손실을 방지한다. 

<br/>

### 카프카의 동작 과정

- **프로듀서는 메시지를 토픽에 전송**: 프로듀서는 데이터(레코드)를 카프카 클러스터에 전송한다. 프로듀서는 데이터를 특정 토픽에 전송한다.
- **브로커는 메시지를 토픽 내 파티션에 저장**: 카프카 클러스터의 브로커가 프로듀서로부터 데이터를 수신하고, 해당 데이터를 지정된 파티션에 기록한다. 각 파티션은 독립적으로 데이터를 순서대로 저장하며, 데이터는 고유한 오프셋(offset)을 부여받는다. 데이터는 로그 형태로 저장되고, 해당 오프셋을 통해 데이터의 순서를 관리한다.
- **컨슈머가 메시지를 구독**: 카프카의 컨슈머는 특정 주제를 구독하고, 해당 주제의 파티션에서 데이터를 소비한다. 컨슈머는 데이터를 순차적으로 읽거나 병렬로 읽을 수 있다.
- **컨슈머가 메시지를 읽음**: 컨슈머는 카프카의 토픽에서 데이터를 읽어들인다. 컨슈머는 특정 토픽의 특정 파티션에 저장된 데이터를 읽어들인다.
- **컨슈머 그룹**: 하나의 토픽에 대해 여러 컨슈머가 존재할 경우, 컨슈머 그룹을 통해 데이터를 분배하여 병렬 처리한다. 각 컨슈머는 파티션을 독립적으로 처리하며, 중복된 메시지 처리 없이 작업을 나눈다.
- **메시지의 오프셋 관리**: 카프카는 각 데이터를 고유한 오프셋으로 식별한다. 컨슈머는 오프셋을 기준으로 데이터를 읽는다.
- **주키퍼로 상태 관리**: 카프카의 주키퍼는 클러스터의 메타데이터와 상태를 관리한다. 주키퍼는 브로커의 등록과 클러스터의 상태를 모니터링한다.
- **레플리케이션**: 카프카는 메시지의 내구성을 보장하기 위해, 데이터를 여러 브로커에 복제한다. 멀티 브로커 환경에서 메시지는 복제본을 통해 다른 브로커에 저장되고, 브로커가 다운되더라도 복제본이 저장된 브로커를 통해서 데이터 손실을 방지한다. 각 파티션은 리더(Leader)와 팔로워(Follower)로 구성된다. 리더는 데이터를 읽고 쓰는 작업을 담당하며, 팔로워는 리더의 데이터를 복제한다.

<br/>
<br/>

## Zookeeper

주키퍼는 분산 시스템을 위한 중앙 집중형 서비스로, 분산 애플리케이션을 위한 코디네이션 서비스를 제공하는데 사용된다. 코디네이션 서비스라는 것은 분산 시스템에서 여러 컴포넌트(서버, 애플리케이션 등) 간의 상호작용을 조정하고 관리하는 서비스를 말한다.  
카프카는 Zookeeper를 활용하여 클러스터의 메타데이터를 관리하고, 브로커들의 상태를 추적하며, 파티션 리더를 선출하는 등 여러 관리 작업을 수행한다.  

주키퍼는 일반적으로 테스트 목적이 아닌 이상 3개 이상의 인스턴스를 권장하며 과반수 투표를 통해 리더를 선출하고, 과반수 이상의 인스턴스가 살아있어야 정상 동작하기 때문에 홀수 개의 인스턴스를 권장한다.  

<br/>

### Zookeeper 주요 기능

- **클러스터 관리:** 주키퍼는 카프카 클러스터의 브로커들을 관리한다. 카프카 브로커가 시작되거나 종료될 때 주키퍼는 해당 브로커의 상태를 추적하고, 이를 클러스터의 다른 브로커들이 인식할 수 있게 한다. 그리고 클러스터 내의 브로커들이 서로 통신할 수 있게 조정하는 역할을 한다.
- **메타데이터 저장:** 카프카는 토픽, 파티션, 리더 정보 등 클러스터의 메타데이터를 주키퍼에 저장한다. 특정 토픽의 파티션이 어느 브로커에 할당되어 있는지, 각 파티션의 리더는 누구인지 등의 정보를 주키퍼가 관리한다. 카프카 브로커들은 이 정보를 주키퍼에서 읽어들여 작업을 수행한다.
- **리더 선출:** 카프카 클러스터 내에서 각 파티션의 리더는 중요한 역할을 한다. 리더는 해당 파티션에 대한 읽기 및 쓰기 요청을 처리하며, 팔로워 브로커들은 리더를 따라 데이터를 복제한다. 주키퍼는 리더 선출 과정에서 중요한 역할을 한다. 특정 파티션에 대한 리더가 실패하면 주키퍼가 새로운 리더를 선출하여 장애를 최소화한다.
- **분산 잠금:** 주키퍼는 분산 환경에서의 동기화를 지원한다. 카프카에서 여러 브로커가 동일한 리소스를 동시에 수정할 경우, 주키퍼는 이를 관리하는 역할을 한다. 예를 들어, 토픽을 생성하거나 삭제할 때 주키퍼가 잠금을 사용하여 동시에 작업을 수행하는 것을 방지한다.
- **헬스 체크 및 장애 감지**: 주키퍼는 각 브로커의 상태를 모니터링한다. 각 브로커는 일정 간격으로 주키퍼에 헬스 체크를 보내며, 이를 통해 주키퍼는 해당 브로커가 정상적으로 동작하는지 확인한다. 만약 헬스 체크가 일정 시간 동안 수신되지 않으면 주키퍼는 해당 브로커를 장애 상태로 간주하고, 해당 브로커에 할당된 파티션의 리더를 다른 브로커로 자동으로 이전시킨다. 이를 통해 클러스터의 가용성을 높인다.

<br/>

### Zookeeper 주의 사항

우선 주의할점이 있다. 주키퍼와 카프카에 대해서 설명하기 전에 자신의 카프카 버전을 확인해야 한다.  

아파치 카프카의 3.5버전 이후부터는 주키퍼를 지원 중단으로 표시한다. 다음은 공식 문서의 주키퍼에 대한 내용이다.

> ### ZooKeeper Deprecation
> With the release of Apache Kafka 3.5, Zookeeper is now marked deprecated. Removal of ZooKeeper is planned in the next major release of Apache Kafka (version 4.0), which is scheduled to happen no sooner than April 2024. During the deprecation phase, ZooKeeper is still supported for metadata management of Kafka clusters, but it is not recommended for new deployments. There is a small subset of features that remain to be implemented in KRaft see current missing features for more information.
> ### Migration
> Users are recommended to begin planning for migration to KRaft and also begin testing to provide any feedback. Refer to ZooKeeper to KRaft Migration for details on how to perform a live migration from ZooKeeper to KRaft and current limitations.

공식 문서의 내용을 보면 3.5버전 출시됨에 따라 주키퍼를 Deprecated 표시 했고, 주키퍼의 제거는 4.0 버전에서 계획됐으며, 새로운 배포에는 권장되지 않으므로 KRaft를 사용한 마이그레이션을 준비하라고 설명되어 있다.  
KRaft 모드는 카프카 자체적으로 메타데이터를 관리하는 방식으로, Zookeeper 없이 카프카 클러스터를 운영할 수 있게 된다. KRaft 모드는 Zookeeper의 중앙 집중형 관리 시스템을 대체하고, 카프카의 모든 메타데이터와 클러스터 상태를 Raft 알고리즘을 통해 관리한다.  

카프카 브로커와 주키퍼를 사용할 것이라면 3.5 이하의 버전을 사용하는 것이 좋다.  

<br/>
<br/>
